{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd712412",
   "metadata": {},
   "source": [
    "El programa utiliza OpenCV y YOLO para crear un sistema de filtros visuales basados en emociones utilizando la webcam.\n",
    "También carga imágenes PNG y GIF que sirven como filtros superpuestos (globos, regalos, vómito, lluvia, fuego y arañas).\n",
    "\n",
    "El programa abre la cámara y procesa cada fotograma en tiempo real. Obtiene la región del rostro y, con dicha región, detecta la emoción más probable mediante el segundo modelo YOLO.\n",
    "Según la detección realizada, escribe el nombre de la emoción sobre la imagen y superpone un filtro animado o estático encima de la cara.\n",
    "\n",
    "Existen dos modos opcionales cuyas instrucciones se muestran en el propio fotograma:\n",
    "\n",
    "El modo p, que muestra las bounding boxes de detección facial.\n",
    "\n",
    "El modo c, que muestra el crop de la cara detectada.\n",
    "\n",
    "Con la tecla q se cierra el programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46931190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.conv import Conv2d\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# FIX para Conv2d, que daba error de compatibilidad por el modelo de detección de caras\n",
    "def _patched_conv_forward(self, input, weight, bias):\n",
    "    dilation = self.dilation\n",
    "    if isinstance(dilation, tuple):\n",
    "        dilation = tuple(int(x) for x in dilation)\n",
    "    else:\n",
    "        dilation = int(dilation)\n",
    "\n",
    "    stride = self.stride\n",
    "    padding = self.padding\n",
    "\n",
    "    if self.padding_mode != \"zeros\":\n",
    "        return F.conv2d(\n",
    "            F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
    "            weight,\n",
    "            bias,\n",
    "            stride,\n",
    "            (0, 0),\n",
    "            dilation,\n",
    "            self.groups,\n",
    "        )\n",
    "\n",
    "    return F.conv2d(input, weight, bias, stride, padding, dilation, self.groups)\n",
    "\n",
    "Conv2d._conv_forward = _patched_conv_forward\n",
    "\n",
    "# MODELOS\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "face_model = YOLO(\"weights/yolov8-lite-t.pt\")\n",
    "emotion_model = YOLO(\"weights/best.pt\")\n",
    "\n",
    "EMOTION_LABELS = [\n",
    "    'Enfadado',\n",
    "    'Contento',\n",
    "    'Disgustado',\n",
    "    'Asustado',\n",
    "    'Feliz',\n",
    "    'Neutral',\n",
    "    'Triste',\n",
    "    'Sorprendido'\n",
    "]\n",
    "\n",
    "# MÉTODOS PARA CARGA Y SUPERPOSICIÓN DE LAS IMÁGENES\n",
    "\n",
    "def preescale_png(path, fixed_width):\n",
    "    png = cv2.imread(path, cv2.IMREAD_UNCHANGED)  # RGBA\n",
    "    if png is None:\n",
    "        raise FileNotFoundError(f\"No se pudo cargar el PNG: {path}\")\n",
    "\n",
    "    orig_h, orig_w = png.shape[:2]\n",
    "\n",
    "    scale = fixed_width / orig_w\n",
    "    new_h = int(orig_h * scale)\n",
    "\n",
    "    png_fixed = cv2.resize(png, (fixed_width, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return png_fixed\n",
    "\n",
    "def gif_loader(path):\n",
    "    gif_frames = []\n",
    "    gif = Image.open(path)\n",
    "    try:\n",
    "        while True:\n",
    "            frame = gif.convert(\"RGBA\")\n",
    "            frame_np = np.array(frame)\n",
    "            frame_bgra = cv2.cvtColor(frame_np, cv2.COLOR_RGBA2BGRA)\n",
    "            gif_frames.append(frame_bgra)\n",
    "            gif.seek(gif.tell() + 1)\n",
    "    except EOFError:\n",
    "        pass\n",
    "    frame_idx = 0\n",
    "    return gif_frames, frame_idx\n",
    "\n",
    "def overlay_rgba(base_img, rgba_img, x, y, scale=1.0):\n",
    "    h_png, w_png = rgba_img.shape[:2]\n",
    "    new_w = int(w_png * scale)\n",
    "    new_h = int(h_png * scale)\n",
    "    if new_w <= 0 or new_h <= 0:\n",
    "        return\n",
    "\n",
    "    resized = cv2.resize(rgba_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    if resized.shape[2] == 4:\n",
    "        bgr = resized[:, :, :3]\n",
    "        alpha = resized[:, :, 3].astype(float) / 255.0  # (H, W)\n",
    "    else:\n",
    "        bgr = resized\n",
    "        alpha = np.ones((new_h, new_w), dtype=float)\n",
    "\n",
    "    H, W = base_img.shape[:2]\n",
    "\n",
    "    x1 = max(0, x)\n",
    "    y1 = max(0, y)\n",
    "    x2 = min(W, x1 + new_w)\n",
    "    y2 = min(H, y1 + new_h)\n",
    "\n",
    "    if x1 >= W or y1 >= H or x2 <= 0 or y2 <= 0:\n",
    "        return\n",
    "\n",
    "    bgr = bgr[0:y2 - y1, 0:x2 - x1]\n",
    "    alpha = alpha[0:y2 - y1, 0:x2 - x1]\n",
    "\n",
    "    roi = base_img[y1:y2, x1:x2]\n",
    "\n",
    "    alpha_3 = alpha[:, :, None]\n",
    "\n",
    "    base_img[y1:y2, x1:x2] = (bgr * alpha_3 + roi * (1.0 - alpha_3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "def overlay_png(base_img, png_img, x, y, scale=1.0):\n",
    "    h_png, w_png = png_img.shape[:2]\n",
    "    new_w = int(w_png * scale)\n",
    "    new_h = int(h_png * scale)\n",
    "    if new_w <= 0 or new_h <= 0:\n",
    "        return\n",
    "\n",
    "    png_resized = cv2.resize(png_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    bgr = png_resized[:, :, :3]\n",
    "    alpha = png_resized[:, :, 3] / 255.0  # 0–1\n",
    "\n",
    "    H, W = base_img.shape[:2]\n",
    "\n",
    "    x1 = max(0, x)\n",
    "    y1 = max(0, y)\n",
    "    x2 = min(W, x1 + new_w)\n",
    "    y2 = min(H, y1 + new_h)\n",
    "\n",
    "    if x1 >= W or y1 >= H:\n",
    "        return\n",
    "\n",
    "    bgr = bgr[0: y2 - y1, 0: x2 - x1]\n",
    "    alpha = alpha[0: y2 - y1, 0: x2 - x1]\n",
    "\n",
    "    roi = base_img[y1:y2, x1:x2]\n",
    "\n",
    "    for c in range(3):\n",
    "        roi[:, :, c] = (bgr[:, :, c] * alpha + roi[:, :, c] * (1 - alpha)).astype(np.uint8)\n",
    "\n",
    "    base_img[y1:y2, x1:x2] = roi\n",
    "\n",
    "# FUNCIONES DE FILTRO\n",
    "\n",
    "def draw_png(img, x1, y1, x2, y2, png_fixed):\n",
    "    new_h, new_w = png_fixed.shape[:2]\n",
    "\n",
    "    face_width = x2 - x1\n",
    "    face_center = x1 + face_width // 2\n",
    "\n",
    "    margin = 10\n",
    "    top_left_x = face_center - new_w // 2\n",
    "    top_left_y = y1 - new_h - margin\n",
    "\n",
    "    overlay_png(img, png_fixed, top_left_x, top_left_y)\n",
    "\n",
    "def draw_rain(img, x1, y1, x2, y2):\n",
    "    h, w, _ = img.shape\n",
    "    rx1 = max(0, x1 - 20)\n",
    "    rx2 = min(w - 1, x2 + 20)\n",
    "    ry1 = max(0, y1 - 40)\n",
    "    ry2 = min(h - 1, y2 + 40)\n",
    "\n",
    "    for _ in range(40):\n",
    "        x = random.randint(rx1, rx2)\n",
    "        y_start = random.randint(ry1, ry2 - 10)\n",
    "        y_end = min(h - 1, y_start + random.randint(10, 25))\n",
    "        cv2.line(img, (x, y_start), (x, y_end), (255, 255, 255), 1)\n",
    "\n",
    "def draw_gif(img, x1, y1, x2, y2, frames, frame_idx, speed=1, scale_div=2.2, scale_min=0.3, scale_max=1.2, y_offset_factor=0.1):\n",
    "    if not frames:\n",
    "        return frame_idx\n",
    "\n",
    "    face_width = x2 - x1\n",
    "    if face_width <= 0:\n",
    "        return frame_idx\n",
    "\n",
    "    base_h, base_w = frames[0].shape[:2]\n",
    "\n",
    "    scale = face_width / (scale_div * base_w)\n",
    "    scale = max(scale_min, min(scale, scale_max))\n",
    "\n",
    "    new_w = int(base_w * scale)\n",
    "    new_h = int(base_h * scale)\n",
    "\n",
    "    face_center = x1 + face_width // 2\n",
    "\n",
    "    top_left_x = face_center - new_w // 2\n",
    "    top_left_y = y2 - int(new_h * y_offset_factor)\n",
    "\n",
    "    frame = frames[frame_idx % len(frames)]\n",
    "\n",
    "    overlay_rgba(img, frame, top_left_x, top_left_y, scale=scale)\n",
    "\n",
    "    return frame_idx + speed\n",
    "\n",
    "# CARGA DE IMÁGENES, GIFS Y LOOP DE LA WEBCAM\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "FIXED_WIDTH = 100\n",
    "balloon_png = preescale_png(\"images/balloons.png\", FIXED_WIDTH)\n",
    "gifts_png = preescale_png(\"images/gifts.png\", FIXED_WIDTH)\n",
    "vomit_png = preescale_png(\"images/vomit.png\", FIXED_WIDTH)\n",
    "ellipsis_png = preescale_png(\"images/ellipsis.png\", FIXED_WIDTH)\n",
    "contempt_png = preescale_png(\"images/contempt.png\", FIXED_WIDTH)\n",
    "\n",
    "fire_gif_frames, fire_frame_idx = gif_loader(\"images/fire.gif\")\n",
    "\n",
    "spiders_gif_frames, spiders_frame_idx = gif_loader(\"images/spiders.gif\")\n",
    "\n",
    "draw_boxes_mode = False\n",
    "face_detection_mode = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detección de caras\n",
    "    face_results = face_model(frame, conf=0.3, verbose=False)\n",
    "    if draw_boxes_mode:\n",
    "        annotated = face_results[0].plot()\n",
    "    else:\n",
    "        annotated = frame.copy()\n",
    "    boxes = face_results[0].boxes\n",
    "\n",
    "    if boxes is not None and len(boxes) > 0:\n",
    "        for box in boxes:\n",
    "            # Coordenadas de la caja de la cara\n",
    "            x1, y1, x2, y2 = box.xyxy[0].int().tolist()\n",
    "\n",
    "            h, w, _ = frame.shape\n",
    "            x1 = max(0, min(x1, w - 1))\n",
    "            x2 = max(0, min(x2, w - 1))\n",
    "            y1 = max(0, min(y1, h - 1))\n",
    "            y2 = max(0, min(y2, h - 1))\n",
    "            if x2 <= x1 or y2 <= y1:\n",
    "                continue\n",
    "\n",
    "            face_crop = frame[y1:y2, x1:x2]\n",
    "            if face_crop.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Detección de emoción sobre el crop\n",
    "            emo_results = emotion_model(face_crop, conf=0.25, verbose=False)\n",
    "            if face_detection_mode:\n",
    "                annotated = emo_results[0].plot()\n",
    "            emo_boxes = emo_results[0].boxes\n",
    "\n",
    "            if emo_boxes is None or len(emo_boxes) == 0:\n",
    "                continue\n",
    "\n",
    "            # Detección de emoción con mayor confianza\n",
    "            confs = emo_boxes.conf\n",
    "            best_idx = int(confs.argmax().item())\n",
    "            cls_id = int(emo_boxes.cls[best_idx].item())\n",
    "\n",
    "            if 0 <= cls_id < len(EMOTION_LABELS):\n",
    "                emotion = EMOTION_LABELS[cls_id]\n",
    "            else:\n",
    "                emotion = \"Unknown\"\n",
    "\n",
    "            cv2.putText(\n",
    "                annotated,\n",
    "                emotion,\n",
    "                (x1, max(y1 - 10, 0)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.8,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "            # Se aplica filtro según emoción\n",
    "            if not draw_boxes_mode and not face_detection_mode:\n",
    "                if emotion == 'Feliz':\n",
    "                    draw_png(annotated, x1, y1, x2, y2, balloon_png)\n",
    "                elif emotion == 'Triste':\n",
    "                    draw_rain(annotated, x1, y1, x2, y2)\n",
    "                elif emotion == 'Enfadado':\n",
    "                    fire_frame_idx = draw_gif(annotated, x1, y1, x2, y2, frames=fire_gif_frames, frame_idx=fire_frame_idx)\n",
    "                elif emotion == 'Sorprendido':\n",
    "                    draw_png(annotated, x1, y1, x2, y2, gifts_png)\n",
    "                elif emotion == 'Disgustado':\n",
    "                    draw_png(annotated, x1, y1, x2, y2, vomit_png)\n",
    "                elif emotion == 'Neutral':\n",
    "                    draw_png(annotated, x1, y1, x2, y2, ellipsis_png)\n",
    "                elif emotion == 'Contento':\n",
    "                    draw_png(annotated, x1, y1, x2, y2, contempt_png)\n",
    "                elif emotion == 'Asustado':\n",
    "                    spiders_frame_idx = draw_gif(annotated, x1, y1, x2, y2, frames=spiders_gif_frames, frame_idx=spiders_frame_idx, speed=4)\n",
    "    \n",
    "    if not draw_boxes_mode and not face_detection_mode:\n",
    "        cv2.putText(\n",
    "                annotated,\n",
    "                \"Usa q para salir\",\n",
    "                (10, 20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "        cv2.putText(\n",
    "                    annotated,\n",
    "                    \"Usa p para ver la bounding box de la cara\",\n",
    "                    (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0, 255, 0),\n",
    "                    2,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "        cv2.putText(\n",
    "                    annotated,\n",
    "                    \"Usa c para ver el crop de la cara\",\n",
    "                    (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0, 255, 0),\n",
    "                    2,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    cv2.imshow(\"Filtro de emociones\", annotated)\n",
    "    \n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    elif key == ord(\"p\"):\n",
    "        draw_boxes_mode = not draw_boxes_mode\n",
    "    elif key == ord(\"c\"):\n",
    "        face_detection_mode = not face_detection_mode\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909d75e",
   "metadata": {},
   "source": [
    "Este programa usa OpenCV y MTCNN para detectar rostros y puntos clave de la cara en tiempo real mediante la webcam. Luego superpone varios elementos PNG transparentes para crear un filtro al estilo Charlie Chaplin, mientras convierte la imagen final a escala de grises.\n",
    "\n",
    "Primero se cargan cuatro imágenes PNG con canal alfa (sombrero, bigote y cejas).\n",
    "A continuación, se inicia el detector MTCNN y la captura de video.\n",
    "\n",
    "El programa procesa cada fotograma de la webcam y detecta rostros usando MTCNN. Si no encuentra ninguno, muestra el video en blanco y negro sin aplicar filtros.\n",
    "\n",
    "Para cada detección obtiene los puntos clave del rostro y, a partir de ellos, calcula las posiciones y tamaños adecuados de cada elemento del filtro. Luego, cada PNG se redimensiona y se superpone en el fotograma utilizando su canal alfa.\n",
    "\n",
    "Antes de mostrar el resultado, la imagen completa se convierte a escala de grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52d759",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# Cargar PNGs con canal alfa\n",
    "chaplin_hat = cv2.imread(\"images/chaplin_hat.png\", cv2.IMREAD_UNCHANGED)\n",
    "chaplin_mustache = cv2.imread(\"images/chaplin_moustache.png\", cv2.IMREAD_UNCHANGED)\n",
    "chaplin_letfeye = cv2.imread(\"images/chaplin_left_eye.png\", cv2.IMREAD_UNCHANGED)\n",
    "chaplin_righteye = cv2.imread(\"images/chaplin_right_eye.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "mtcnn_det = MTCNN()\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "def overlay(fondo, img, x, y):\n",
    "    fh, fw = fondo.shape[:2]\n",
    "    ih, iw = img.shape[:2]\n",
    "\n",
    "    if x >= fw or y >= fh:\n",
    "        return fondo\n",
    "\n",
    "    # calcular límites \n",
    "    w = min(iw, fw - x)\n",
    "    h = min(ih, fh - y)\n",
    "\n",
    "    # recortar imagen si se sale\n",
    "    img = img[0:h, 0:w]\n",
    "\n",
    "    # separar canales\n",
    "    overlay_rgb = img[:, :, :3]\n",
    "    alpha = img[:, :, 3:] / 255.0\n",
    "\n",
    "    #montar imagen\n",
    "    fondo[y:y+h, x:x+w] = (1 - alpha) * fondo[y:y+h, x:x+w] + alpha * overlay_rgb\n",
    "    return fondo\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = mtcnn_det.detect_faces(rgb_frame)\n",
    "\n",
    "    if len(results) == 0:\n",
    "        # si no hay cara mostrar sin filtro\n",
    "        cv2.imshow(\"Chaplin filter\", cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    #coger primera cara detectada\n",
    "    for result in results:\n",
    "        keypoints = result[\"keypoints\"]\n",
    "\n",
    "        left_eye = keypoints[\"left_eye\"]\n",
    "        right_eye = keypoints[\"right_eye\"]\n",
    "        mouth_left = keypoints[\"mouth_left\"]\n",
    "        mouth_right = keypoints[\"mouth_right\"]\n",
    "\n",
    "        # Centro de ojos\n",
    "        eye_center_x = int((left_eye[0] + right_eye[0]) / 2)\n",
    "        eye_center_y = int((left_eye[1] + right_eye[1]) / 2)\n",
    "\n",
    "        eye_distance = abs(right_eye[0] - left_eye[0])\n",
    "\n",
    "        #sombrero\n",
    "        hat_width = int(3 * eye_distance) \n",
    "        hat_height = int(hat_width * chaplin_hat.shape[0] / chaplin_hat.shape[1])\n",
    "\n",
    "        x_hat = eye_center_x - hat_width // 2\n",
    "        y_hat = eye_center_y - int(hat_height * 1.25)\n",
    "\n",
    "        hat_resize = cv2.resize(chaplin_hat, (hat_width, hat_height))\n",
    "        frame = overlay(frame, hat_resize, x_hat, y_hat)\n",
    "\n",
    "        #bigote\n",
    "        mouth_width = abs(mouth_right[0] - mouth_left[0])\n",
    "        mustache_width = int(0.9 * mouth_width) \n",
    "        mustache_height = int(mustache_width * chaplin_mustache.shape[0] / chaplin_mustache.shape[1])\n",
    "\n",
    "        mouth_center_x = int((mouth_left[0] + mouth_right[0]) / 2)\n",
    "        mouth_center_y = int((mouth_left[1] + mouth_right[1]) / 2)\n",
    "\n",
    "        x_m = mouth_center_x - mustache_width // 2\n",
    "        y_m = mouth_center_y - mustache_height  \n",
    "\n",
    "        mustache_resize = cv2.resize(chaplin_mustache, (mustache_width, mustache_height))\n",
    "        frame = overlay(frame, mustache_resize, x_m, y_m)\n",
    "\n",
    "        # cejas\n",
    "        eyebrow_width = int(1.6 * abs(right_eye[0] - left_eye[0]) * 0.5)\n",
    "        eyebrow_height = int(eyebrow_width * chaplin_letfeye.shape[0] / chaplin_letfeye.shape[1])\n",
    "\n",
    "        # Resize\n",
    "        left_eyebrow_r = cv2.resize(chaplin_letfeye, (eyebrow_width, eyebrow_height))\n",
    "        right_eyebrow_r = cv2.resize(chaplin_righteye, (eyebrow_width, eyebrow_height))\n",
    "\n",
    "        x_left_eyebrow = int(left_eye[0] - eyebrow_width/1.8)\n",
    "        y_left_eyebrow = int(left_eye[1] - eyebrow_height*1)\n",
    "\n",
    "        x_right_eyebrow = int(right_eye[0] - eyebrow_width/2)\n",
    "        y_right_eyebrow = int(right_eye[1] - eyebrow_height*1.1)\n",
    "\n",
    "        #  overlay\n",
    "        frame = overlay(frame, left_eyebrow_r,  x_left_eyebrow,  y_left_eyebrow)\n",
    "        frame = overlay(frame, right_eyebrow_r, x_right_eyebrow, y_right_eyebrow)\n",
    "\n",
    "            \n",
    "        # Mostrar en gris\n",
    "        background_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        background_gray = cv2.cvtColor(background_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        cv2.imshow('Chaplin filter', background_gray)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
