{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322c3a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevin\\Ingeniería informática\\Cuarto\\VC\\P5\\entregable\\ultralytics\\yolo\\utils\\checks.py:17: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources as pkg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.conv import Conv2d\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# FIX para Conv2d, que daba error de compatibilidad por el modelo de detección de caras\n",
    "def _patched_conv_forward(self, input, weight, bias):\n",
    "    dilation = self.dilation\n",
    "    if isinstance(dilation, tuple):\n",
    "        dilation = tuple(int(x) for x in dilation)\n",
    "    else:\n",
    "        dilation = int(dilation)\n",
    "\n",
    "    stride = self.stride\n",
    "    padding = self.padding\n",
    "\n",
    "    if self.padding_mode != \"zeros\":\n",
    "        return F.conv2d(\n",
    "            F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
    "            weight,\n",
    "            bias,\n",
    "            stride,\n",
    "            (0, 0),\n",
    "            dilation,\n",
    "            self.groups,\n",
    "        )\n",
    "\n",
    "    return F.conv2d(input, weight, bias, stride, padding, dilation, self.groups)\n",
    "\n",
    "Conv2d._conv_forward = _patched_conv_forward\n",
    "\n",
    "# MODELOS\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "face_model = YOLO(\"weights/yolov8-lite-t.pt\")\n",
    "emotion_model = YOLO(\"weights/best.pt\")\n",
    "\n",
    "EMOTION_LABELS = [\n",
    "    'Enfadado',\n",
    "    'Contento',\n",
    "    'Disgustado',\n",
    "    'Asustado',\n",
    "    'Feliz',\n",
    "    'Neutral',\n",
    "    'Triste',\n",
    "    'Sorprendido'\n",
    "]\n",
    "\n",
    "# MÉTODOS PARA CARGA Y SUPERPOSICIÓN DE LAS IMÁGENES\n",
    "\n",
    "def preescale_png(path, fixed_width):\n",
    "    png = cv2.imread(path, cv2.IMREAD_UNCHANGED)  # RGBA\n",
    "    if png is None:\n",
    "        raise FileNotFoundError(f\"No se pudo cargar el PNG: {path}\")\n",
    "\n",
    "    orig_h, orig_w = png.shape[:2]\n",
    "\n",
    "    scale = fixed_width / orig_w\n",
    "    new_h = int(orig_h * scale)\n",
    "\n",
    "    png_fixed = cv2.resize(png, (fixed_width, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return png_fixed\n",
    "\n",
    "def gif_loader(path):\n",
    "    gif_frames = []\n",
    "    gif = Image.open(path)\n",
    "    try:\n",
    "        while True:\n",
    "            frame = gif.convert(\"RGBA\")\n",
    "            frame_np = np.array(frame)\n",
    "            frame_bgra = cv2.cvtColor(frame_np, cv2.COLOR_RGBA2BGRA)\n",
    "            gif_frames.append(frame_bgra)\n",
    "            gif.seek(gif.tell() + 1)\n",
    "    except EOFError:\n",
    "        pass\n",
    "    frame_idx = 0\n",
    "    return gif_frames, frame_idx\n",
    "\n",
    "def overlay_rgba(base_img, rgba_img, x, y, scale=1.0):\n",
    "    h_png, w_png = rgba_img.shape[:2]\n",
    "    new_w = int(w_png * scale)\n",
    "    new_h = int(h_png * scale)\n",
    "    if new_w <= 0 or new_h <= 0:\n",
    "        return\n",
    "\n",
    "    resized = cv2.resize(rgba_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    if resized.shape[2] == 4:\n",
    "        bgr = resized[:, :, :3]\n",
    "        alpha = resized[:, :, 3].astype(float) / 255.0  # (H, W)\n",
    "    else:\n",
    "        bgr = resized\n",
    "        alpha = np.ones((new_h, new_w), dtype=float)\n",
    "\n",
    "    H, W = base_img.shape[:2]\n",
    "\n",
    "    x1 = max(0, x)\n",
    "    y1 = max(0, y)\n",
    "    x2 = min(W, x1 + new_w)\n",
    "    y2 = min(H, y1 + new_h)\n",
    "\n",
    "    if x1 >= W or y1 >= H or x2 <= 0 or y2 <= 0:\n",
    "        return\n",
    "\n",
    "    bgr = bgr[0:y2 - y1, 0:x2 - x1]\n",
    "    alpha = alpha[0:y2 - y1, 0:x2 - x1]\n",
    "\n",
    "    roi = base_img[y1:y2, x1:x2]\n",
    "\n",
    "    alpha_3 = alpha[:, :, None]\n",
    "\n",
    "    base_img[y1:y2, x1:x2] = (bgr * alpha_3 + roi * (1.0 - alpha_3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "def overlay_png(base_img, png_img, x, y, scale=1.0):\n",
    "    h_png, w_png = png_img.shape[:2]\n",
    "    new_w = int(w_png * scale)\n",
    "    new_h = int(h_png * scale)\n",
    "    if new_w <= 0 or new_h <= 0:\n",
    "        return\n",
    "\n",
    "    png_resized = cv2.resize(png_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    bgr = png_resized[:, :, :3]\n",
    "    alpha = png_resized[:, :, 3] / 255.0  # 0–1\n",
    "\n",
    "    H, W = base_img.shape[:2]\n",
    "\n",
    "    x1 = max(0, x)\n",
    "    y1 = max(0, y)\n",
    "    x2 = min(W, x1 + new_w)\n",
    "    y2 = min(H, y1 + new_h)\n",
    "\n",
    "    if x1 >= W or y1 >= H:\n",
    "        return\n",
    "\n",
    "    bgr = bgr[0: y2 - y1, 0: x2 - x1]\n",
    "    alpha = alpha[0: y2 - y1, 0: x2 - x1]\n",
    "\n",
    "    roi = base_img[y1:y2, x1:x2]\n",
    "\n",
    "    for c in range(3):\n",
    "        roi[:, :, c] = (bgr[:, :, c] * alpha + roi[:, :, c] * (1 - alpha)).astype(np.uint8)\n",
    "\n",
    "    base_img[y1:y2, x1:x2] = roi\n",
    "\n",
    "# FUNCIONES DE FILTRO\n",
    "\n",
    "def draw_png(img, x1, y1, x2, y2, png_fixed):\n",
    "    new_h, new_w = png_fixed.shape[:2]\n",
    "\n",
    "    face_width = x2 - x1\n",
    "    face_center = x1 + face_width // 2\n",
    "\n",
    "    margin = 10\n",
    "    top_left_x = face_center - new_w // 2\n",
    "    top_left_y = y1 - new_h - margin\n",
    "\n",
    "    overlay_png(img, png_fixed, top_left_x, top_left_y)\n",
    "\n",
    "def draw_rain(img, x1, y1, x2, y2):\n",
    "    h, w, _ = img.shape\n",
    "    rx1 = max(0, x1 - 20)\n",
    "    rx2 = min(w - 1, x2 + 20)\n",
    "    ry1 = max(0, y1 - 40)\n",
    "    ry2 = min(h - 1, y2 + 40)\n",
    "\n",
    "    for _ in range(40):\n",
    "        x = random.randint(rx1, rx2)\n",
    "        y_start = random.randint(ry1, ry2 - 10)\n",
    "        y_end = min(h - 1, y_start + random.randint(10, 25))\n",
    "        cv2.line(img, (x, y_start), (x, y_end), (255, 255, 255), 1)\n",
    "\n",
    "def draw_gif(img, x1, y1, x2, y2, frames, frame_idx, speed=1, scale_div=2.2, scale_min=0.3, scale_max=1.2, y_offset_factor=0.1):\n",
    "    if not frames:\n",
    "        return frame_idx\n",
    "\n",
    "    face_width = x2 - x1\n",
    "    if face_width <= 0:\n",
    "        return frame_idx\n",
    "\n",
    "    base_h, base_w = frames[0].shape[:2]\n",
    "\n",
    "    scale = face_width / (scale_div * base_w)\n",
    "    scale = max(scale_min, min(scale, scale_max))\n",
    "\n",
    "    new_w = int(base_w * scale)\n",
    "    new_h = int(base_h * scale)\n",
    "\n",
    "    face_center = x1 + face_width // 2\n",
    "\n",
    "    top_left_x = face_center - new_w // 2\n",
    "    top_left_y = y2 - int(new_h * y_offset_factor)\n",
    "\n",
    "    frame = frames[frame_idx % len(frames)]\n",
    "\n",
    "    overlay_rgba(img, frame, top_left_x, top_left_y, scale=scale)\n",
    "\n",
    "    return frame_idx + speed\n",
    "\n",
    "# CARGA DE IMÁGENES, GIFS Y LOOP DE LA WEBCAM\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "FIXED_WIDTH = 150\n",
    "balloon_png = preescale_png(\"images/balloons.png\", FIXED_WIDTH)\n",
    "gifts_png = preescale_png(\"images/gifts.png\", FIXED_WIDTH)\n",
    "vomit_png = preescale_png(\"images/vomit.png\", FIXED_WIDTH)\n",
    "ellipsis_png = preescale_png(\"images/ellipsis.png\", FIXED_WIDTH)\n",
    "contempt_png = preescale_png(\"images/contempt.png\", FIXED_WIDTH)\n",
    "\n",
    "fire_gif_frames, fire_frame_idx = gif_loader(\"images/fire.gif\")\n",
    "\n",
    "spiders_gif_frames, spiders_frame_idx = gif_loader(\"images/spiders.gif\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detección de caras\n",
    "    face_results = face_model(frame, conf=0.3, verbose=False)\n",
    "\n",
    "    annotated = frame.copy()\n",
    "    boxes = face_results[0].boxes\n",
    "\n",
    "    if boxes is not None and len(boxes) > 0:\n",
    "        for box in boxes:\n",
    "            # Coordenadas de la caja de la cara\n",
    "            x1, y1, x2, y2 = box.xyxy[0].int().tolist()\n",
    "\n",
    "            h, w, _ = frame.shape\n",
    "            x1 = max(0, min(x1, w - 1))\n",
    "            x2 = max(0, min(x2, w - 1))\n",
    "            y1 = max(0, min(y1, h - 1))\n",
    "            y2 = max(0, min(y2, h - 1))\n",
    "            if x2 <= x1 or y2 <= y1:\n",
    "                continue\n",
    "\n",
    "            face_crop = frame[y1:y2, x1:x2]\n",
    "            if face_crop.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Detección de emoción sobre el crop\n",
    "            emo_results = emotion_model(face_crop, conf=0.25, verbose=False)\n",
    "            emo_boxes = emo_results[0].boxes\n",
    "\n",
    "            if emo_boxes is None or len(emo_boxes) == 0:\n",
    "                continue\n",
    "\n",
    "            # Detección de emoción con mayor confianza\n",
    "            confs = emo_boxes.conf\n",
    "            best_idx = int(confs.argmax().item())\n",
    "            cls_id = int(emo_boxes.cls[best_idx].item())\n",
    "\n",
    "            if 0 <= cls_id < len(EMOTION_LABELS):\n",
    "                emotion = EMOTION_LABELS[cls_id]\n",
    "            else:\n",
    "                emotion = \"Unknown\"\n",
    "\n",
    "            cv2.putText(\n",
    "                annotated,\n",
    "                emotion,\n",
    "                (x1, max(y1 - 10, 0)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.8,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "            # Se aplica filtro según emoción\n",
    "            if emotion == 'Feliz':\n",
    "                draw_png(annotated, x1, y1, x2, y2, balloon_png)\n",
    "            elif emotion == 'Triste':\n",
    "                draw_rain(annotated, x1, y1, x2, y2)\n",
    "            elif emotion == 'Enfadado':\n",
    "                fire_frame_idx = draw_gif(annotated, x1, y1, x2, y2, frames=fire_gif_frames, frame_idx=fire_frame_idx)\n",
    "            elif emotion == 'Sorprendido':\n",
    "                draw_png(annotated, x1, y1, x2, y2, gifts_png)\n",
    "            elif emotion == 'Disgustado':\n",
    "                draw_png(annotated, x1, y1, x2, y2, vomit_png)\n",
    "            elif emotion == 'Neutral':\n",
    "                draw_png(annotated, x1, y1, x2, y2, ellipsis_png)\n",
    "            elif emotion == 'Contento':\n",
    "                draw_png(annotated, x1, y1, x2, y2, contempt_png)\n",
    "            elif emotion == 'Asustado':\n",
    "                spiders_frame_idx = draw_gif(annotated, x1, y1, x2, y2, frames=spiders_gif_frames, frame_idx=spiders_frame_idx, speed=4)\n",
    "\n",
    "    cv2.imshow(\"Filtro de emociones\", annotated)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
